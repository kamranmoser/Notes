Absolutely — here’s a clean, copy-and-paste–ready version formatted perfectly for email. It’s concise, professional, and governance-friendly, while still capturing the full discussion.

⸻

Subject: TechADS PARCM Calculation Walkthrough – Meeting Notes & Key Takeaways

Hi everyone,

Below are the meeting notes and key takeaways from the TechADS PARCM calculation walkthrough. This session covered how daily DQ controls roll up into monthly PARCM metrics, how exclusions are handled, and how final results are packaged and submitted.

⸻

Purpose of Session
	•	Walk through the end-to-end TechADS PARCM calculation process
	•	Demonstrate how daily DQC monitoring feeds monthly PARCM metrics
	•	Review root cause analysis, exclusions, and governance artifacts

⸻

PARCM Metric Overview
	•	DQ-001 – Data ingestion received and processed correctly and on time
	•	DQ-002 – Data provisioning completed correctly and on time
	•	DQ-003 – Data quality checks (nulls, duplicates, etc.) passing

PARCM is a monthly aggregation fully driven by daily DQC monitoring (no separate calculation logic).

⸻

Inputs to PARCM
	•	SLA checks (upstream and downstream)
	•	GVR checks
	•	API checks
	•	Null and duplicate checks

Metrics are calculated by:
	•	Determining pass / fail / total counts at the control level
	•	Rolling results up to the metric level
	•	Calculating % pass = pass ÷ total

⸻

Walkthrough Highlights
	•	PARCM processor was pre-run for the Application Domain
	•	Metric-level view shows each control contributing to PARCM
	•	Analysts primarily work from the exported Excel file, not the UI
	•	Raw data is reviewed first, followed by RCA and exclusions

⸻

Root Cause Analysis & Exclusions
	•	Each failure is reviewed day by day
	•	For planned outages:
	•	Failures are excluded
	•	SLA windows are adjusted by outage duration
	•	If recovered within the adjusted window, the run is treated as a pass
	•	All exclusions are documented with outage details, ownership, and justification
	•	Exclusions are tracked for audit traceability

⸻

Results & Reporting
	•	After RCA and exclusions:
	•	Updated files are re-uploaded into the app
	•	Final metrics are generated
	•	A PowerPoint is created for governance review
	•	If a metric is yellow or red, a formal Action Plan is required
	•	Includes breach summary, root cause, and remediation plan

⸻

SLA & Configuration Notes
	•	SLAs are driven by TechADS SLA configuration tables
	•	Logic aligns with DSA documentation
	•	Queries used are documented in the Control Metric Document
	•	Historical raw data is available; post-RCA historical views are planned

⸻

Provisioning Clarifications
	•	DQ-002 includes target table availability, distribution, and API access
	•	API metrics represent successful consumer pulls
	•	Consumer lists are informational; calculations are based on successful interactions
	•	Documentation wording will be updated to reflect current provisioning behavior

⸻

Governance Considerations
	•	Metric percentages are submitted first to ORCIT
	•	Commentary and action plans require governance review, especially for upstream issues
	•	Submission language must be carefully reviewed due to CIO dashboard visibility
	•	Exclusions and remediation details should also be reflected in the Control Metric Document

⸻

Future Enhancements (In Progress)
	•	Automated persistence of RCA and exclusions in the database
	•	One-click ORCIT submissions
	•	Centralized PARCM module on the TechADS dashboard
	•	Full historical audit traceability
	•	Reduced reliance on SharePoint as an interim step

⸻

Key Takeaways
	•	PARCM is fully driven by daily DQC monitoring
	•	RCA and exclusions are critical to accurate reporting
	•	Planned outages are handled via SLA window adjustments
	•	The current process is governance-sound and audit-ready

Please let me know if there are any questions or if additional follow-ups are needed.

Thanks,
Kamran

⸻

If you want, I can also:
	•	Shorten this into an exec-level summary
	•	Pull out explicit action items by owner
	•	Reformat it for Confluence or governance documentation